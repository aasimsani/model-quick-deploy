{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Quick Deploy V2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aasimsani/model-quick-deploy/blob/main/Model_Quick_Deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tA2E7UY4YzW"
      },
      "source": [
        "# Install requirements "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz7ghcWAatK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc15c92b-d9bc-43d6-e6d7-03cda99d943c"
      },
      "source": [
        "# Install requirements\n",
        "!pip install fastapi==0.68.1\n",
        "!pip install opencv-python==4.5.3.56\n",
        "# !pip install Pillow==8.3.2\n",
        "!pip install timm==0.4.12\n",
        "!pip install python-multipart==0.0.5\n",
        "!pip install uvicorn==0.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi==0.68.1 in /usr/local/lib/python3.7/dist-packages (0.68.1)\n",
            "Requirement already satisfied: starlette==0.14.2 in /usr/local/lib/python3.7/dist-packages (from fastapi==0.68.1) (0.14.2)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi==0.68.1) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.68.1) (3.10.0.2)\n",
            "Requirement already satisfied: opencv-python==4.5.3.56 in /usr/local/lib/python3.7/dist-packages (4.5.3.56)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.3.56) (1.19.5)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.7/dist-packages (0.4.12)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm==0.4.12) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.4.12) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm==0.4.12) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.12) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.12) (1.19.5)\n",
            "Requirement already satisfied: python-multipart==0.0.5 in /usr/local/lib/python3.7/dist-packages (0.0.5)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from python-multipart==0.0.5) (1.15.0)\n",
            "Requirement already satisfied: uvicorn==0.15.0 in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.15.0) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.15.0) (3.10.0.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.15.0) (0.12.0)\n",
            "Requirement already satisfied: asgiref>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.15.0) (3.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokMreh-e2YC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68de44e7-fec6-4e55-bf0e-8b97961e52cc"
      },
      "source": [
        "!pip install nest-asyncio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYDZfIQ0ljYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f61386-f3e4-4ec7-9d63-19d291b1f87e"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import HTMLResponse, StreamingResponse\n",
        "\n",
        "import cv2\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure"
      ],
      "metadata": {
        "id": "EIQ3BGWgNAe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DPT Model"
      ],
      "metadata": {
        "id": "CBkSccNGQhE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_dpt(model_type):\n",
        "  ## Load model\n",
        "  \n",
        "  # MiDaS v3 - Large\n",
        "  # (highest accuracy, slowest inference speed)\n",
        "  # model_type = \"DPT_Large\"  \n",
        "  \n",
        "  # MiDaS v3 - Hybrid\n",
        "  # (medium accuracy, medium inference speed)\n",
        "  # model_type = \"DPT_Hybrid\"\n",
        "  \n",
        "  # (lowest accuracy, highest inference speed)\n",
        "  # model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small\n",
        "  \n",
        "  midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "  \n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  midas.to(device)\n",
        "  midas.eval()\n",
        "\n",
        "  return midas  \n",
        "\n",
        "\n",
        "def pre_process_dpt(image, model_type):\n",
        "\n",
        "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "    if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "        transform = midas_transforms.dpt_transform\n",
        "    else:\n",
        "        transform = midas_transforms.small_transfor\n",
        "\n",
        "    # Load image\n",
        "    img = cv2.imdecode(np.frombuffer(image.file.read(),\n",
        "                                      np.uint8),\n",
        "                        cv2.IMREAD_COLOR)\n",
        "\n",
        "    # convert it to the correct format\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Transform it so that it can be used by the model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    input_batch = transform(img).to(device)\n",
        "\n",
        "    # Return this image so it can be used in postprocessing\n",
        "    return input_batch, img\n",
        "\n",
        "def post_process_dpt(original, prediction):\n",
        "\n",
        "  prediction = torch.nn.functional.interpolate(\n",
        "                prediction.unsqueeze(1),\n",
        "                size=original.shape[:2],\n",
        "                mode=\"bicubic\",\n",
        "                align_corners=False,\n",
        "            ).squeeze()\n",
        "\n",
        "  output = prediction.cpu().numpy()\n",
        "  # Create a figure using matplotlib which super-imposes the original\n",
        "  # image and the prediction\n",
        "\n",
        "  fig = Figure()\n",
        "  canvas = FigureCanvas(fig)\n",
        "  ax = fig.gca()\n",
        "\n",
        "  # Render both images original as foreground\n",
        "  ax.imshow(original)\n",
        "  ax.imshow(output)\n",
        "\n",
        "  ax.axis(\"off\")\n",
        "  canvas.draw()\n",
        "\n",
        "  # Reshape output to be a numpy array\n",
        "  width, height = fig.get_size_inches() * fig.get_dpi()\n",
        "  width = int(width)\n",
        "  height = int(height)\n",
        "  output_image = np.frombuffer(canvas.tostring_rgb(),\n",
        "                                dtype='uint8').reshape(height, width, 3)\n",
        "\n",
        "  # Encode to png\n",
        "  res, im_png = cv2.imencode(\".png\", output_image)\n",
        "\n",
        "  return im_png\n",
        "\n"
      ],
      "metadata": {
        "id": "rsCQ-SqcLLVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd4njq644OGL"
      },
      "source": [
        "# Setup the server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANG-77q5arAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67bb128-4ed4-491c-93a8-ecd8c5ff5ebc"
      },
      "source": [
        "\n",
        "model_type = \"DPT_Large\"\n",
        "model = load_model_dpt(model_type)\n",
        "\n",
        "# Code from: https://fastapi.tiangolo.com/tutorial/request-files/\n",
        "app = FastAPI()\n",
        "\n",
        "\n",
        "@app.post(\"/uploadfiles/\")\n",
        "async def create_upload_files(files: List[UploadFile] = File(...)):\n",
        "    \"\"\" Create API endpoint to send image to and specify\n",
        "     what type of file it'll take\n",
        "\n",
        "    :param files: Get image files, defaults to File(...)\n",
        "    :type files: List[UploadFile], optional\n",
        "    :return: A list of png images\n",
        "    :rtype: list(bytes)\n",
        "    \"\"\"\n",
        "\n",
        "    for image in files:\n",
        "\n",
        "        # Return preprocessed input batch and loaded image\n",
        "        input_batch, image = pre_process_dpt(image, model_type)\n",
        "\n",
        "        # Run the model and postpocess the output\n",
        "        with torch.no_grad():\n",
        "            prediction = model(input_batch)\n",
        "\n",
        "        # # Post process and stitch together the two images to return them\n",
        "        output_image = post_process_dpt(image, prediction)\n",
        "            \n",
        "        return StreamingResponse(io.BytesIO(output_image.tobytes()),\n",
        "                                 media_type=\"image/png\")\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def main():\n",
        "    \"\"\"Create a basic home page to upload a file\n",
        "\n",
        "    :return: HTML for homepage\n",
        "    :rtype: HTMLResponse\n",
        "    \"\"\"\n",
        "\n",
        "    content = \"\"\"<body>\n",
        "          <h3>Upload an image to get it's depth map from the MiDaS model</h3>\n",
        "          <form action=\"/uploadfiles/\" enctype=\"multipart/form-data\" method=\"post\">\n",
        "              <input name=\"files\" type=\"file\" multiple>\n",
        "              <input type=\"submit\">\n",
        "          </form>\n",
        "      </body>\n",
        "      \"\"\"\n",
        "    return HTMLResponse(content=content)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBbE8OI8fOVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07fcd0a9-0a8e-4606-c373-9411d258f699"
      },
      "source": [
        "auth_token = \"\" #@param {type:\"string\"}\n",
        "# Since we can't access Colab notebooks IP directly we'll use\n",
        "# ngrok to create a public URL for the server via a tunnel\n",
        "\n",
        "# Authenticate ngrok\n",
        "# https://dashboard.ngrok.com/signup\n",
        "# Then go to the \"Your Authtoken\" tab in the sidebar and copy the API key\n",
        "import os\n",
        "os.system(f\"ngrok authtoken {auth_token}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHrh3rOnmtuA"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Create tunnel\n",
        "public_url = ngrok.connect(8000, port='8000', bind_tls=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hqiEAo5PpLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069a1211-13f3-4c5b-c4e0-d8a2e68f19e0"
      },
      "source": [
        "# Check if it exists\n",
        "!ps aux | grep ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        1069  8.0  0.1 726652 24592 ?        Sl   04:51   0:00 /usr/local/lib/python3.7/dist-packages/pyngrok/bin/ngrok start --none --log=stdout\n",
            "root        1079  0.0  0.0  39196  6352 ?        S    04:51   0:00 /bin/bash -c ps aux | grep ngrok\n",
            "root        1081  0.0  0.0  38572  5576 ?        S    04:51   0:00 grep ngrok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NVUy4iL43jg"
      },
      "source": [
        "# Make magic happen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggazuIY0auLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1e2651-7d23-4010-9a48-87a66827638a"
      },
      "source": [
        "import nest_asyncio\n",
        "\n",
        "# Allow for asyncio to work within the Jupyter notebook cell\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import uvicorn\n",
        "\n",
        "# Run the FastAPI app using uvicorn\n",
        "print(public_url)\n",
        "uvicorn.run(app)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [997]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://6c4b-34-80-230-51.ngrok.io\" -> \"http://localhost:8000\"\n",
            "INFO:     143.215.193.201:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     73.141.27.108:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     73.141.27.108:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     69.59.197.164:0 - \"GET /uploadfiles/ HTTP/1.1\" 405 Method Not Allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     73.141.27.108:0 - \"POST /uploadfiles/ HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [997]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAgM7AQHgh8N"
      },
      "source": [
        "# Kill tunnel\n",
        "ngrok.disconnect(public_url=public_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "30W96DhCN05k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}