{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Quick Deploy",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aasimsani/model-quick-deploy/blob/main/Model_Quick_Deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tA2E7UY4YzW"
      },
      "source": [
        "# Install requirements "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz7ghcWAatK5"
      },
      "source": [
        "# Install requirements\n",
        "!pip install fastapi==0.68.1\n",
        "!pip install opencv-python==4.5.3.56\n",
        "!pip insall Pillow==8.3.2\n",
        "!pip install timm==0.4.12\n",
        "!pip install python-multipart==0.0.5\n",
        "!pip install uvicorn==0.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokMreh-e2YC"
      },
      "source": [
        "!pip install nest-asyncio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYDZfIQ0ljYx"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd4njq644OGL"
      },
      "source": [
        "# Setup the server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANG-77q5arAo"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import HTMLResponse, StreamingResponse\n",
        "\n",
        "import cv2\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure\n",
        "\n",
        "## Load model\n",
        "\n",
        "# MiDaS v3 - Large\n",
        "# (highest accuracy, slowest inference speed)\n",
        "\n",
        "model_type = \"DPT_Large\"\n",
        "\n",
        "# MiDaS v3 - Hybrid\n",
        "# (medium accuracy, medium inference speed)\n",
        "# model_type = \"DPT_Hybrid\"\n",
        "\n",
        "# (lowest accuracy, highest inference speed)\n",
        "# model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small\n",
        "\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform\n",
        "\n",
        "# Code from: https://fastapi.tiangolo.com/tutorial/request-files/\n",
        "app = FastAPI()\n",
        "\n",
        "\n",
        "@app.post(\"/uploadfiles/\")\n",
        "async def create_upload_files(files: List[UploadFile] = File(...)):\n",
        "    \"\"\" Create API endpoint to send image to and specify\n",
        "     what type of file it'll take\n",
        "\n",
        "    :param files: Get image files, defaults to File(...)\n",
        "    :type files: List[UploadFile], optional\n",
        "    :return: A list of png images\n",
        "    :rtype: list(bytes)\n",
        "    \"\"\"\n",
        "\n",
        "    for image in files:\n",
        "\n",
        "        # Load image\n",
        "        img = cv2.imdecode(np.frombuffer(image.file.read(),\n",
        "                                         np.uint8),\n",
        "                           cv2.IMREAD_COLOR)\n",
        "\n",
        "        # convert it to the correct format\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Transform it so that it can be used by the model\n",
        "        input_batch = transform(img).to(device)\n",
        "\n",
        "        # Run the model and postpocess the output\n",
        "        with torch.no_grad():\n",
        "            prediction = midas(input_batch)\n",
        "\n",
        "            prediction = torch.nn.functional.interpolate(\n",
        "                prediction.unsqueeze(1),\n",
        "                size=img.shape[:2],\n",
        "                mode=\"bicubic\",\n",
        "                align_corners=False,\n",
        "            ).squeeze()\n",
        "\n",
        "        output = prediction.cpu().numpy()\n",
        "\n",
        "        # Create a figure using matplotlib which super-imposes the original\n",
        "        # image and the prediction\n",
        "\n",
        "        fig = Figure()\n",
        "        canvas = FigureCanvas(fig)\n",
        "        ax = fig.gca()\n",
        "\n",
        "        # Render both images original as foreground\n",
        "        ax.imshow(img)\n",
        "        ax.imshow(output, cmap=\"jet\", alpha=0.8)\n",
        "\n",
        "        ax.axis(\"off\")\n",
        "        canvas.draw()\n",
        "\n",
        "        # Reshape output to be a numpy array\n",
        "        width, height = fig.get_size_inches() * fig.get_dpi()\n",
        "        width = int(width)\n",
        "        height = int(height)\n",
        "        output_image = np.frombuffer(canvas.tostring_rgb(),\n",
        "                                     dtype='uint8').reshape(height, width, 3)\n",
        "\n",
        "        # Encode to png\n",
        "        res, im_png = cv2.imencode(\".png\", output_image)\n",
        "        return StreamingResponse(io.BytesIO(im_png.tobytes()),\n",
        "                                 media_type=\"image/png\")\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def main():\n",
        "    \"\"\"Create a basic home page to upload a file\n",
        "\n",
        "    :return: HTML for homepage\n",
        "    :rtype: HTMLResponse\n",
        "    \"\"\"\n",
        "\n",
        "    content = \"\"\"<body>\n",
        "          <h3>Upload an image to get it's depth map from the MiDaS model</h3>\n",
        "          <form action=\"/uploadfiles/\" enctype=\"multipart/form-data\" method=\"post\">\n",
        "              <input name=\"files\" type=\"file\" multiple>\n",
        "              <input type=\"submit\">\n",
        "          </form>\n",
        "      </body>\n",
        "      \"\"\"\n",
        "    return HTMLResponse(content=content)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBbE8OI8fOVa"
      },
      "source": [
        "auth_token = \"\" #@param {type:\"string\"}\n",
        "# Since we can't access Colab notebooks IP directly we'll use\n",
        "# ngrok to create a public URL for the server via a tunnel\n",
        "\n",
        "# Authenticate ngrok\n",
        "# https://dashboard.ngrok.com/signup\n",
        "# Then go to the \"Your Authtoken\" tab in the sidebar and copy the API key\n",
        "import os\n",
        "os.system(f\"ngrok authtoken {auth_token}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHrh3rOnmtuA"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Create tunnel\n",
        "public_url = ngrok.connect(8000, port='8000')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hqiEAo5PpLu"
      },
      "source": [
        "# Check if it exists\n",
        "!ps aux | grep ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NVUy4iL43jg"
      },
      "source": [
        "# Make magic happen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggazuIY0auLI"
      },
      "source": [
        "import nest_asyncio\n",
        "\n",
        "# Allow for asyncio to work within the Jupyter notebook cell\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import uvicorn\n",
        "\n",
        "# Run the FastAPI app using uvicorn\n",
        "print(public_url)\n",
        "uvicorn.run(app)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAgM7AQHgh8N"
      },
      "source": [
        "# Kill tunnel\n",
        "ngrok.disconnect(public_url=public_url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}